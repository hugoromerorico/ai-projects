{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept/concept.py\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")\n",
    "import json\n",
    "\n",
    "# Initialize Vertex AI with your project ID and location\n",
    "vertexai.init(project=\"mm-cia-dev\", location=\"europe-west1\")  # Replace with your project ID and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the name of a sibling\n",
    "def get_sibling(sibling: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns the name of a sibling based on the type.\n",
    "    \"\"\"\n",
    "    if sibling.lower() == \"sister\":\n",
    "        return {\"result\": \"Mary\"}\n",
    "    elif sibling.lower() == \"brother\":\n",
    "        return {\"result\": \"John\"}\n",
    "    else:\n",
    "        return {\"result\": \"Unknown\"}\n",
    "\n",
    "get_sibling_func = FunctionDeclaration(\n",
    "    name=\"get_sibling\",\n",
    "    description=\"Returns the name of a sibling based on the type.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"sibling\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Type of sibling (e.g., sister, brother)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"sibling\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "sibling_tool = Tool(\n",
    "    function_declarations=[get_sibling_func],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sibling_tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m user_prompt_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you give me the name of my sister?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize the Gemini model with the specified tools\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m GenerativeModel(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Replace with your desired Gemini model ID\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     system_instruction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant that can answer questions and help with tasks. You have tools to get the name of a sibling. If the user ask for a name you can use a tool to get either the name of the brother or the sister, depending on what the user ask for.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mGenerationConfig(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m---> 11\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[\u001b[43msibling_tool\u001b[49m],\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Generate content with the user prompt\u001b[39;00m\n\u001b[1;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m     16\u001b[0m     user_prompt_content,\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sibling_tool' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the tool that includes the function declaration\n",
    "# Define the user's prompt as a Content object\n",
    "user_prompt_content = \"Can you give me the name of my sister?\"\n",
    "\n",
    "\n",
    "# Initialize the Gemini model with the specified tools\n",
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-flash-002\",  # Replace with your desired Gemini model ID\n",
    "    system_instruction=\"You are a helpful assistant that can answer questions and help with tasks. You have tools to get the name of a sibling. If the user ask for a name you can use a tool to get either the name of the brother or the sister, depending on what the user ask for.\",\n",
    "    generation_config=GenerationConfig(temperature=0.5),\n",
    "    tools=[sibling_tool],\n",
    ")\n",
    "\n",
    "# Generate content with the user prompt\n",
    "response = model.generate_content(\n",
    "    user_prompt_content,\n",
    ")\n",
    "print(\"Response:\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "# Extract the function call from the model's response\n",
    "function_call = response.candidates[0].function_calls[0]\n",
    "\n",
    "print(\"Function Call Detected:\")\n",
    "print(json.dumps(function_call, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: 100386322.\n",
      "View Weave data at https://wandb.ai/100386322/castor-concept/weave\n",
      "üç© https://wandb.ai/100386322/castor-concept/r/call/0192c5a6-89bd-75e1-b99a-a3a3ff6a29e1\n",
      "Response:\n",
      "# Google Cloud Gemini Hackathon\n",
      "\n",
      "**This hackathon is open to registrants from Europe, Middle East and Africa (specific countries).**\n",
      "\n",
      "## Overview\n",
      "\n",
      "<p>Welcome to the Google Cloud Gemini Hackathon! Join us for an exciting hackathon where creativity meets cutting-edge technology. We invite developers, innovators, and tech enthusiasts to come together and build groundbreaking applications using the Gemini API, in either Google AI Studio or Vertex AI environment. This is your chance to create solutions that not only showcase your skills but also address some of the most pressing challenges in the modern world.</p>\n",
      "\n",
      "\n",
      "**Join Hackathon:** [https://googlecloudgeminihackathon.devpost.com/register?flow%5Bdata%5D%5Bchallenge_id%5D=22241&amp;flow%5Bname%5D=register_for_challenge](https://googlecloudgeminihackathon.devpost.com/register?flow%5Bdata%5D%5Bchallenge_id%5D=22241&amp;flow%5Bname%5D=register_for_challenge)\n",
      "\n",
      "**Deadline:** Nov 11, 2024 @ 5:00pm GMT\n",
      "\n",
      "\n",
      "### Eligibility\n",
      "\n",
      "*   Ages 18+ only\n",
      "*   Only specific countries/territories included: Algeria, Angola, Austria, Bahrain, Belgium, Benin, Botswana, Bulgaria, Burkina Faso, Burundi, Cameroon, Central African Republic, Chad, Comoros, Congo the Democratic Republic of the, Croatia, Czech Republic, Denmark, Djibouti, Egypt, Equatorial Guinea, Eritrea, Estonia, Ethiopia, Finland, France, Gabon, Gambia, Georgia, Germany, Ghana, Gibraltar, Greece, Guernsey, Guinea, Guinea-Bissau, Hungary, Iceland, Iraq, Ireland, Isle of Man, Israel, Italy, Jersey, Jordan, Kenya, Kuwait, Latvia, Lebanon, Lesotho, Liberia, Libyan Arab Jamahiriya, Liechtenstein, Lithuania, Luxembourg, Madagascar, Malawi, Mali, Malta, Mauritania, Mauritius, Morocco, Mozambique, Namibia, Netherlands, Niger, Nigeria, Norway, Oman, Palestine State of, Poland, Portugal, Qatar, Romania, Rwanda, Sao Tome and Principe, Saudi Arabia, Senegal, Slovakia, Slovenia, Somalia, South Africa, Spain, Swaziland, Sweden, Switzerland, Tanzania United Republic of, Togo, Tunisia, Turkey, Uganda, United Arab Emirates, United Kingdom, Western Sahara, Yemen, Zambia, Zimbabwe\n",
      "\n",
      "[View full rules](/rules)\n",
      "\n",
      "\n",
      "## Requirements\n",
      "\n",
      "### What to Build\n",
      "\n",
      "This hackathon is your playground to create or modify an application that leverages the power of the Gemini API, in either the Google AI Studio or Vertex AI environment. Whether you're focused on Security, Sovereignty, Sustainability, or the Smart Use of Data and AI, the possibilities are endless. Your innovation could be the next big thing in:\n",
      "\n",
      "1.  **Security**: Develop solutions like Cloud Workload Protection, Phishing Detection, or a Threat Intelligence Platform to safeguard our digital world.\n",
      "2.  **Sovereignty**: Create tools that facilitate cybersecurity cooperation between nations, assess data sovereignty risks, or ensure compliance with data localization regulations.\n",
      "3.  **Sustainability**: Design apps that promote sustainable sourcing, integrate renewable energy, or automate energy audits to drive a greener future.\n",
      "4.  **Smart Use of Data & AI**: Innovate with AI Ethics Frameworks, customer service chatbots, explainable AI systems, or predictive analytics for business forecasting.\n",
      "\n",
      "\n",
      "### What to Submit\n",
      "\n",
      "*   Project built with Google Gemini API, in either Google AI Studio, or Vertex AI environment\n",
      "*   Public link to your project for judges to test\n",
      "*   Google Project ID\n",
      "*   Public code repository showing use of Gemini product within your idea\n",
      "*   Text description that includes a summary of the Project‚Äôs features and functionality\n",
      "*   ~3-minute demonstration video of your Project\n",
      "\n",
      "\n",
      "## Prizes\n",
      "\n",
      "**$20,000 in prizes**\n",
      "\n",
      "*   **1st Place:** $7,500 in USD, 30-minute Virtual Meeting with a Google Team Member, Social Promo of the Project\n",
      "*   **2nd Place:** $5,000 in USD, 30-minute Virtual Meeting with a Google Team Member, Social Promo of the Project\n",
      "*   **3rd Place:** $2,500 in USD, 30-minute Virtual Meeting with a Google Team Member, Social Promo of the Project\n",
      "*   **Honorable Mentions (5):** $1,000 in USD, 30-minute Virtual Meeting with a Google Team Member, Social Promo of the Project\n",
      "\n",
      "\n",
      "## Judges\n",
      "\n",
      "*   **Benjamin Sadik**: _Customer Engineer_\n",
      "*   **Catayoun Azarm**: _Customer Engineer_\n",
      "*   **Eloise de Carvalho**: _Customer Engineer_\n",
      "*   **Kimoon Kim**: _Customer Engineer_\n",
      "*   **Marco Acunzo**: _Customer Engineer_\n",
      "\n",
      "\n",
      "## Judging Criteria\n",
      "\n",
      "*   **Technological Implementation**: Does the interaction with the Gemini API demonstrate quality software development?\n",
      "*   **Design**: Is the user experience and design of the project well thought out?\n",
      "*   **Potential Impact**: How big of an impact could the project have on the Security, Sovereignty, Sustainability or Data and AI sectors?\n",
      "*   **Quality of Idea**: How creative and unique is the project?\n",
      "\n",
      "\n",
      "## Sponsors\n",
      "\n",
      "[Google Cloud](https://s3.amazonaws.com/challengepost/sponsors/logos/000/037/005/highres/logo_cloud_color.png)\n",
      "\n",
      "\n",
      "## Contact\n",
      "\n",
      "Questions? Email the hackathon manager: shawni@devpost.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\n",
    "    \"gemini-1.5-flash-002\",  # Replace with your desired Gemini model ID\n",
    "    system_instruction=\"You are an expert in transforming the content of webpages into structured markdown. You just receive the result from curl and you need to transform it into markdown.\",\n",
    "    generation_config=GenerationConfig(temperature=0.5),\n",
    ")\n",
    "# Curl \"https://googlecloudgeminihackathon.devpost.com/?ref_feature=challenge&ref_medium=discover\"\n",
    "import requests\n",
    "\n",
    "# Fetch content from the URL\n",
    "url = \"https://googlecloudgeminihackathon.devpost.com/?ref_feature=challenge&ref_medium=discover\"\n",
    "page_content = requests.get(url).text\n",
    "\n",
    "import weave\n",
    "# Generate content with the user prompt\n",
    "weave.init(\"castor-concept\")\n",
    "\n",
    "@weave.op()\n",
    "def main(page_content: str):\n",
    "    response = model.generate_content(\n",
    "        page_content)\n",
    "    return response\n",
    "\n",
    "response = main(page_content)\n",
    "print(\"Response:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Execute the function based on the model's function call\n",
    "if function_call.name == function_name:\n",
    "    sibling_type = function_call.args[\"sibling\"]\n",
    "    function_result = get_sibling(sibling_type)\n",
    "    print(\"\\nFunction Execution Result:\")\n",
    "    print(json.dumps(function_result, indent=4))\n",
    "\n",
    "    # Prepare the function response as Content\n",
    "    function_response_content = Content(\n",
    "        role=\"function\",\n",
    "        name=function_name,\n",
    "        parts=[\n",
    "            Part.from_function_response(\n",
    "                name=function_name,\n",
    "                response=function_result\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Generate the final model response with the function result\n",
    "    final_response = model.generate_content(\n",
    "        [\n",
    "            user_prompt_content,          # User prompt\n",
    "            response.candidates[0].content,  # Function call response\n",
    "            function_response_content     # Function execution result\n",
    "        ],\n",
    "        tools=[sibling_tool],\n",
    "    )\n",
    "\n",
    "    print(\"\\nFinal Model Response:\")\n",
    "    print(final_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
